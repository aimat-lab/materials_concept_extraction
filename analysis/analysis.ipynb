{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58d42c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195370/195370 [00:06<00:00, 31373.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_csv(\"../data/concepts.csv\")\n",
    "df.concepts = df.concepts.progress_apply(lambda x: set(literal_eval(x)))\n",
    "\n",
    "concepts = Counter()\n",
    "for concept_list in df.concepts:\n",
    "    concepts.update(concept_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4305b2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384427"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts.most_common(25)\n",
    "# IDEA: automatic merging of highly connected nodes\n",
    "# Can we merge abbreviations with their concepts automatically?\n",
    "len(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0915c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concepts: 1384427 -> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1384427/1384427 [00:00<00:00, 4679835.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147297\n",
      "Building edge list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195370/195370 [00:08<00:00, 22674.76it/s]\n"
     ]
    }
   ],
   "source": [
    "CONCEPTS_COLNAME = \"concepts\"\n",
    "INPUT_FILE = \"../data/concepts.csv\"\n",
    "ORIGIN_DAY = pd.to_datetime(\"1970-01-01\")\n",
    "\n",
    "\n",
    "class OccuranceFilter:\n",
    "    def __init__(self, min_occurance=None, max_occurance=None):\n",
    "        self.min_occurance = min_occurance\n",
    "        self.max_occurance = max_occurance\n",
    "\n",
    "    def __call__(self, concepts):\n",
    "        #print(\n",
    "        #    f\"Applying occurance filter: min={self.min_occurance}, max={self.max_occurance}\"\n",
    "        #)\n",
    "        concepts = {\n",
    "            concept: n\n",
    "            for concept, n in tqdm(concepts.items())\n",
    "            if (self.min_occurance is None or n >= self.min_occurance)\n",
    "            and (self.max_occurance is None or n <= self.max_occurance)\n",
    "        }\n",
    "\n",
    "        return concepts\n",
    "\n",
    "c_filters = [OccuranceFilter(min_occurance=3)]\n",
    "\n",
    "\n",
    "print(f\"Number of concepts: {len(concepts)} -> \", end=\"\")\n",
    "for filter in c_filters:\n",
    "    concepts_filtered = filter(concepts)\n",
    "print(len(concepts_filtered))\n",
    "\n",
    "concept_list = list(concepts_filtered.keys())\n",
    "\n",
    "# transform concepts into numbers\n",
    "lookup = {}\n",
    "for index, concept in enumerate(sorted(concept_list)):\n",
    "    concept = concept.strip()\n",
    "    lookup[concept] = index\n",
    "\n",
    "# save lookup as csv\n",
    "lookup_df = pd.DataFrame.from_dict(lookup, orient=\"index\", columns=[\"id\"])\n",
    "lookup_df.to_csv(\"lookup.csv\")\n",
    "\n",
    "def get_pairs(items):\n",
    "    pairs = []\n",
    "    for i1 in items:\n",
    "        for i2 in items:\n",
    "            if i1 == i2:\n",
    "                # this ensures that we don't get to the diagonal line in the pairing matrix\n",
    "                # as order doesn't matter, this yields just half of the matrix (excluding the diagonal)\n",
    "                break\n",
    "            pairs.append((i1, i2))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "print(\"Building edge list\")\n",
    "all_edges = []\n",
    "for concept_list in tqdm(list(df[CONCEPTS_COLNAME])):\n",
    "    concept_ids = {\n",
    "        lookup[c] for c in concept_list if lookup.get(c) is not None\n",
    "    }  # set comprehension because rake doesn't filter out duplicates\n",
    "\n",
    "    for v1, v2 in get_pairs(concept_ids):\n",
    "        all_edges.append(np.array((v1, v2)))\n",
    "\n",
    "\n",
    "all_edges = np.array(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e55576b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123396,  73153],\n",
       "       [119910,  73153],\n",
       "       [119910, 123396],\n",
       "       [ 73223,  73153],\n",
       "       [ 73223, 123396]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_edges[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
